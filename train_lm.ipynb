{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai2.basics import *\n",
    "from fastai2.text.all import *\n",
    "from fastai2.callback.all import *\n",
    "\n",
    "from transformers import AutoModelWithLMHead, AutoModel, AutoModelForPreTraining, AutoTokenizer, AutoConfig\n",
    "\n",
    "import tqdm\n",
    "import json, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# TODO: clean lines (words longer then 10)\n",
    "# offsets = []\n",
    "# with open(\"he.txt\", \"r\") as file:\n",
    "#     while True:\n",
    "#         line = file.readline()\n",
    "#         if not line:\n",
    "#             break\n",
    "#         offsets.append(file.tell())\n",
    "#         if len(offsets) % 10000 == 0:\n",
    "#             print(len(offsets))\n",
    "# # pickle.dump(offsets, open(\"offsets.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "# lines_offsets = random.choices(offsets, k=1000000)\n",
    "# lines_offsets = sorted(lines_offsets)\n",
    "# create_dict(lines_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OscarDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, indexs):\n",
    "        self.indexs = indexs\n",
    "        self.file = open(\"he.txt\", \"r\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indexs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.get_line(idx)\n",
    "    \n",
    "    \n",
    "    def get_line(self, idx): \n",
    "        point = self.indexs[idx]\n",
    "        self.file.seek(point)\n",
    "        line = self.file.readline()\n",
    "        return line\n",
    "    \n",
    "import sentencepiece\n",
    "import collections\n",
    "import os\n",
    "def create_dict(lines_offsets, size_v=5000, name=\"m\"):\n",
    "    lines = [get_line(offset) for offset in tqdm.tqdm_notebook(lines_offsets)]\n",
    "    if os.path.isfile(\"file.txt\"): os.remove(\"file.txt\")\n",
    "    with open(f\"file.txt\", \"w\") as f:\n",
    "        for w in lines:\n",
    "            f.writelines(w + \"\\n\")\n",
    "\n",
    "    sentencepiece.SentencePieceTrainer.Train(f'--input=file.txt --model_prefix={name} --vocab_size={size_v}')\n",
    "\n",
    "\n",
    "def get_vocab(name = \"row.dic\", path = None):\n",
    "    spm = sentencepiece.SentencePieceProcessor()\n",
    "    spm.file_path = name\n",
    "    spm.Load(spm.file_path)\n",
    "    spm.words = [spm.id_to_piece(id) for id in range(spm.get_piece_size())]\n",
    "    spm.vocab = collections.defaultdict(int,{v:k for k,v in enumerate(spm.words)})         \n",
    "    spm.words_len = len(spm.words)\n",
    "    return spm\n",
    "\n",
    "def get_oscar(bs=4):\n",
    "    train_idx = offsets[:int(len(offsets) * 0.9)]\n",
    "    valid_idx = offsets[int(len(offsets) * 0.9):]\n",
    "    train_ds = OscarDataset(train_idx)\n",
    "    valid_ds = OscarDataset(valid_idx)\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, after_batch=collate_fn)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=bs, after_batch=collate_fn)\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(point): \n",
    "    file.seek(point)\n",
    "    line = file.readline().replace(\"\\n\", \"\")\n",
    "    return line\n",
    "\n",
    "def get_words_by_len():\n",
    "    file = open(\"he.txt\")\n",
    "    lines_offsets = random.choices(offsets, k=100000)\n",
    "    lines_offsets = sorted(lines_offsets)\n",
    "    lines = [get_line(offset) for offset in tqdm.tqdm_notebook(lines_offsets)]\n",
    "    file.close()\n",
    "    words = [j for l in lines for j in l.split(\" \")]\n",
    "    words_count = Counter(words).most_common()\n",
    "    words = [i[0] for i in words_count if i[1] > 5]\n",
    "    words = [i for i in words if len(i) < 10]\n",
    "    words_by_len = {}\n",
    "    for w in words:\n",
    "        subwords = spm.encode_as_pieces(w)\n",
    "        words_by_len.setdefault(len(subwords), []).append(w)\n",
    "    return words_by_len\n",
    "\n",
    "# pickle.dump(words_by_len, open(\"words_by_len.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm = get_vocab(\"./sp_heb.model\")\n",
    "offsets = pickle.load(open(\"offsets.pkl\", \"rb\"))\n",
    "words_by_len = pickle.load(open(\"words_by_len.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_lists(lists, pad_value = 0):\n",
    "    num_of_list = len(lists)\n",
    "    max_len = max([len(i) for i in lists])\n",
    "    pad_tensor  = torch.zeros(num_of_list, max_len).long() + pad_value\n",
    "    for n, t in enumerate(lists):\n",
    "        pad_tensor[n, :len(t)] = torch.tensor(t)\n",
    "    return pad_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/ubuntu/bert/\")\n",
    "from models import Config, Transformer\n",
    "c = Config(vocab_size = spm.words_len, dim=100, n_layers=4, n_heads=4)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.Transformer = Transformer(cfg)\n",
    "        self.layer = nn.Linear(cfg.dim, cfg.vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Transformer(x)\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "m = Model(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_output_from_lines(lines, max_len=512):\n",
    "    input_subwords, target_subword, mask = [], [], []\n",
    "    for line in lines:\n",
    "        line_input_subwords, line_target_subwords, line_mask = [], [], []\n",
    "        words = line.split(\" \")\n",
    "# TODO: shift in some way\n",
    "#         if len(words) > max_len:\n",
    "#             idx = random.randint(0, len(words) - max_len)\n",
    "#             words = words[idx:idx + max_len]\n",
    "        for word in words:\n",
    "            word_subword = spm.encode_as_ids(word)\n",
    "            if len(line_target_subwords) + len(word_subword) > max_len:\n",
    "                continue\n",
    "            line_target_subwords.extend(word_subword)\n",
    "            r = random.random()\n",
    "            if r < 0.15 and len(word_subword) <= 10:\n",
    "                if r < 0.12: # mask\n",
    "                    line_input_subwords.extend([2] * len(word_subword)) \n",
    "                elif r < 0.135: # replace\n",
    "                    random_word = random.choice(words_by_len[len(word_subword)])\n",
    "                    line_input_subwords.extend(spm.encode_as_ids(random_word)) \n",
    "                else: # keep\n",
    "                    line_input_subwords.extend(word_subword)\n",
    "                line_mask.extend([1] * len(word_subword)) \n",
    "            else:\n",
    "                line_input_subwords.extend(word_subword)\n",
    "                line_mask.extend([0] * len(word_subword)) \n",
    "        input_subwords.append(line_input_subwords)\n",
    "        target_subword.append(line_target_subwords)\n",
    "        mask.append(line_mask)\n",
    "    return input_subwords, target_subword, mask\n",
    "\n",
    "def collate_fn(lines):\n",
    "    input_subwords, target_subword, mask = create_input_output_from_lines(lines)    \n",
    "    input_tensor = pad_lists(input_subwords, 1)\n",
    "    target_tensor = pad_lists(target_subword, 1)\n",
    "    mask_tensor = pad_lists(mask)\n",
    "    return input_tensor, [target_tensor, mask_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 154])\n",
      "torch.Size([16, 373])\n",
      "torch.Size([16, 95])\n",
      "torch.Size([16, 243])\n",
      "torch.Size([16, 185])\n",
      "torch.Size([16, 191])\n",
      "torch.Size([16, 161])\n",
      "torch.Size([16, 186])\n",
      "torch.Size([16, 246])\n",
      "torch.Size([16, 336])\n",
      "torch.Size([16, 189])\n",
      "torch.Size([16, 329])\n",
      "torch.Size([16, 254])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 251])\n",
      "torch.Size([16, 178])\n",
      "torch.Size([16, 156])\n",
      "torch.Size([16, 137])\n",
      "torch.Size([16, 151])\n",
      "torch.Size([16, 161])\n",
      "torch.Size([16, 159])\n",
      "torch.Size([16, 264])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 121])\n",
      "torch.Size([16, 180])\n",
      "torch.Size([16, 174])\n",
      "torch.Size([16, 178])\n",
      "torch.Size([16, 353])\n",
      "torch.Size([16, 194])\n",
      "torch.Size([16, 168])\n",
      "torch.Size([16, 450])\n",
      "torch.Size([16, 163])\n",
      "torch.Size([16, 148])\n",
      "torch.Size([16, 265])\n",
      "torch.Size([16, 277])\n",
      "torch.Size([16, 295])\n",
      "torch.Size([16, 444])\n",
      "torch.Size([16, 273])\n",
      "torch.Size([16, 288])\n",
      "torch.Size([16, 384])\n",
      "torch.Size([16, 61])\n",
      "torch.Size([16, 198])\n",
      "torch.Size([16, 458])\n",
      "torch.Size([16, 264])\n",
      "torch.Size([16, 330])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 174])\n",
      "torch.Size([16, 147])\n",
      "torch.Size([16, 350])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 288])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 485])\n",
      "torch.Size([16, 252])\n",
      "torch.Size([16, 264])\n",
      "torch.Size([16, 192])\n",
      "torch.Size([16, 191])\n",
      "torch.Size([16, 222])\n",
      "torch.Size([16, 208])\n",
      "torch.Size([16, 340])\n",
      "torch.Size([16, 102])\n",
      "torch.Size([16, 130])\n",
      "torch.Size([16, 160])\n",
      "torch.Size([16, 421])\n",
      "torch.Size([16, 124])\n",
      "torch.Size([16, 134])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 155])\n",
      "torch.Size([16, 155])\n",
      "torch.Size([16, 88])\n",
      "torch.Size([16, 162])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 156])\n",
      "torch.Size([16, 207])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 307])\n",
      "torch.Size([16, 418])\n",
      "torch.Size([16, 437])\n",
      "torch.Size([16, 319])\n",
      "torch.Size([16, 260])\n",
      "torch.Size([16, 228])\n",
      "torch.Size([16, 497])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 235])\n",
      "torch.Size([16, 146])\n",
      "torch.Size([16, 133])\n",
      "torch.Size([16, 213])\n",
      "torch.Size([16, 328])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 108])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 306])\n",
      "torch.Size([16, 149])\n",
      "torch.Size([16, 160])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 141])\n",
      "torch.Size([16, 152])\n",
      "torch.Size([16, 170])\n",
      "torch.Size([16, 197])\n",
      "torch.Size([16, 187])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 143])\n",
      "torch.Size([16, 120])\n",
      "torch.Size([16, 120])\n",
      "torch.Size([16, 155])\n",
      "torch.Size([16, 157])\n",
      "torch.Size([16, 215])\n",
      "torch.Size([16, 215])\n",
      "torch.Size([16, 235])\n",
      "torch.Size([16, 123])\n",
      "torch.Size([16, 123])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 327])\n",
      "torch.Size([16, 324])\n",
      "torch.Size([16, 147])\n",
      "torch.Size([16, 146])\n",
      "torch.Size([16, 127])\n",
      "torch.Size([16, 130])\n",
      "torch.Size([16, 133])\n",
      "torch.Size([16, 171])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 179])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 130])\n",
      "torch.Size([16, 126])\n",
      "torch.Size([16, 182])\n",
      "torch.Size([16, 144])\n",
      "torch.Size([16, 169])\n",
      "torch.Size([16, 155])\n",
      "torch.Size([16, 155])\n",
      "torch.Size([16, 152])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 251])\n",
      "torch.Size([16, 296])\n",
      "torch.Size([16, 81])\n",
      "torch.Size([16, 58])\n",
      "torch.Size([16, 189])\n",
      "torch.Size([16, 153])\n",
      "torch.Size([16, 319])\n",
      "torch.Size([16, 235])\n",
      "torch.Size([16, 228])\n",
      "torch.Size([16, 197])\n",
      "torch.Size([16, 116])\n",
      "torch.Size([16, 92])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 132])\n",
      "torch.Size([16, 151])\n",
      "torch.Size([16, 81])\n",
      "torch.Size([16, 46])\n",
      "torch.Size([16, 50])\n",
      "torch.Size([16, 50])\n",
      "torch.Size([16, 47])\n",
      "torch.Size([16, 167])\n",
      "torch.Size([16, 74])\n",
      "torch.Size([16, 113])\n",
      "torch.Size([16, 224])\n",
      "torch.Size([16, 88])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 97])\n",
      "torch.Size([16, 268])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 188])\n",
      "torch.Size([16, 182])\n",
      "torch.Size([16, 228])\n",
      "torch.Size([16, 448])\n",
      "torch.Size([16, 421])\n",
      "torch.Size([16, 136])\n",
      "torch.Size([16, 147])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 63])\n",
      "torch.Size([16, 57])\n",
      "torch.Size([16, 58])\n",
      "torch.Size([16, 68])\n",
      "torch.Size([16, 67])\n",
      "torch.Size([16, 63])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 330])\n",
      "torch.Size([16, 179])\n",
      "torch.Size([16, 321])\n",
      "torch.Size([16, 193])\n",
      "torch.Size([16, 199])\n",
      "torch.Size([16, 447])\n",
      "torch.Size([16, 357])\n",
      "torch.Size([16, 126])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 142])\n",
      "torch.Size([16, 254])\n",
      "torch.Size([16, 244])\n",
      "torch.Size([16, 314])\n",
      "torch.Size([16, 238])\n",
      "torch.Size([16, 207])\n",
      "torch.Size([16, 439])\n",
      "torch.Size([16, 179])\n",
      "torch.Size([16, 216])\n",
      "torch.Size([16, 391])\n",
      "torch.Size([16, 246])\n",
      "torch.Size([16, 256])\n",
      "torch.Size([16, 200])\n",
      "torch.Size([16, 226])\n",
      "torch.Size([16, 312])\n",
      "torch.Size([16, 133])\n",
      "torch.Size([16, 382])\n",
      "torch.Size([16, 509])\n",
      "torch.Size([16, 400])\n",
      "torch.Size([16, 507])\n",
      "torch.Size([16, 404])\n",
      "torch.Size([16, 90])\n",
      "torch.Size([16, 228])\n",
      "torch.Size([16, 194])\n",
      "torch.Size([16, 98])\n",
      "torch.Size([16, 102])\n",
      "torch.Size([16, 249])\n",
      "torch.Size([16, 114])\n",
      "torch.Size([16, 389])\n",
      "torch.Size([16, 163])\n",
      "torch.Size([16, 53])\n",
      "torch.Size([16, 55])\n",
      "torch.Size([16, 54])\n",
      "torch.Size([16, 53])\n",
      "torch.Size([16, 52])\n",
      "torch.Size([16, 61])\n",
      "torch.Size([16, 313])\n",
      "torch.Size([16, 141])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 215])\n",
      "torch.Size([16, 247])\n",
      "torch.Size([16, 447])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-48-94876011a1be>\", line 5, in <module>\n",
      "    r = m(x)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-15-72cb819d11ab>\", line 12, in forward\n",
      "    x = self.Transformer(x)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/bert/models.py\", line 154, in forward\n",
      "    h = block(h, mask)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/bert/models.py\", line 138, in forward\n",
      "    h = self.norm2(h + self.drop(self.pwff(h)))\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/bert/models.py\", line 121, in forward\n",
      "    return self.fc2(gelu(self.fc1(x)))\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 87, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py\", line 1372, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "tdl, vdl = get_oscar(16)\n",
    "dls = DataLoaders(*[tdl, vdl])\n",
    "for (x,y) in tdl:\n",
    "    print(x.size())\n",
    "    r = m(x)\n",
    "    _ = loss_func(r, y)\n",
    "    _ = acc_func(r, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(output_tensor, target):\n",
    "    target_tensor, target_mask = target\n",
    "    return F.cross_entropy(output_tensor[target_mask == 1],\n",
    "                           target_tensor[target_mask == 1])\n",
    "\n",
    "def acc_func(output_tensor, target):\n",
    "    target_tensor, target_mask = target\n",
    "    return accuracy(output_tensor[target_mask == 1],\n",
    "                           target_tensor[target_mask == 1].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dls, \n",
    "                  m,\n",
    "                  loss_func=loss_func,\n",
    "                  metrics=[acc_func])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>acc_func</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='16' class='' max='37725508', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [16/37725508 00:37<24631:54:55 nan]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
